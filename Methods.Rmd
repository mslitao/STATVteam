---
title: "Methods"
author: "taol4"
date: "8/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

## Load the data

```{r}
train = read.csv("train.csv")
rownames(train) = train$Id
#train = train[, -which(names(train) %in% c("Id", "Alley", "Utilities", "Condition1", "Condition2","Exterior1st", "Exterior2nd", "FireplaceQu", "PoolQC", "Fence", "MiscFeature"))]

# remove missing data, which is stored as "?"
train = subset(train, train$GarageType != "?")

train = train[which(train$GrLivArea < 4000),]

#Fix some NAs
train$GarageYrBlt[is.na(train$GarageYrBlt)] <- 0
train$MasVnrArea[is.na(train$MasVnrArea)] <- 0
train$LotFrontage[is.na(train$LotFrontage)] <- 0

#train = subset(train, select = c("YearBuilt", "LotArea", "Street", "Heating", "CentralAir", "FullBath", "HalfBath", "BedroomAbvGr", "KitchenQual", "GarageType", "SalePrice"))

train = train[, unlist(lapply(train, is.numeric))]
train = train[, -which(names(train) %in% c("Id"))]


#str(train)
```


## Data Processing

```{r}
#library(car) 
#scatterplot(SalePrice ~ X1stFlrSF, data=train,  xlab="Square Footage Floor 1", ylab="Sale Price", grid=FALSE)

#colnames(train)

#names(train)
numericFeatures = names(train)
numericFeatures = numericFeatures[!numericFeatures %in% c("SalePrice")]

n = length(numericFeatures)
correlations = rep(0.0, n)
correlations_log_na = rep(0.0, n)
correlations_na_log = rep(0.0, n)
correlations_log_log = rep(0.0, n)

for(i in 1:n){
  correlations[i] = cor(train[,numericFeatures[i]], train[,"SalePrice"])
  correlations_log_na[i] = cor(log(train[,numericFeatures[i]] +1), train[,"SalePrice"])
  correlations_na_log[i] = cor(train[,numericFeatures[i]], log(train[,"SalePrice"]))
  correlations_log_log[i] = cor(log(train[,numericFeatures[i]]+1), log(train[,"SalePrice"]))
}



colFeaturesName = rep("", n-1)
colFeaturesCorr = rep(0.0, n-1)

collinearity_mean3 = rep(0.0, n)
collinearity_mean5 = rep(0.0, n)
collinearity_mean = rep(0.0, n)

collinearity_f1 = rep("", n)
collinearity_f2 = rep("", n)
collinearity_f3 = rep("", n)
collinearity_c1 = rep(0.0, n)
collinearity_c2 = rep(0.0, n)
collinearity_c3 = rep(0.0, n)
  
for(i in 1:n){
  index = 1
  for(j in 1:n){
    if(i != j){
      colFeaturesCorr[index] = cor(train[,numericFeatures[i]], train[,numericFeatures[j]])
      colFeaturesName[index] = numericFeatures[j]
      
      index = index +1
      colFeatureStat = data.frame(features = colFeaturesName,
                                  correlations = colFeaturesCorr,
                                  abs_correlations = abs(colFeaturesCorr))
      colFeatureStat = colFeatureStat[order(-colFeatureStat$abs_correlations),]
      collinearity_mean3[i] = mean(colFeatureStat$abs_correlations[c(1:3)])
      collinearity_mean5[i] = mean(colFeatureStat$abs_correlations[c(1:5)])
      collinearity_mean[i] = mean(colFeatureStat$abs_correlations)
      
      collinearity_f1[i] = as.character(colFeatureStat$features[1])
      collinearity_f2[i] = as.character(colFeatureStat$features[2])
      collinearity_f3[i] = as.character(colFeatureStat$features[3])
      
      collinearity_c1[i] = colFeatureStat$correlations[1]
      collinearity_c2[i] = colFeatureStat$correlations[2]
      collinearity_c3[i] = colFeatureStat$correlations[3]
      
    }
  }
  
}

featureStat = data.frame(features = numericFeatures, 
                   correlations = round(correlations,2),
                   abs_correlations = round(abs(correlations),2),
                   correlations_log_na = round(correlations_log_na,2),
                   correlations_na_log = round(correlations_na_log,2),
                   correlations_log_log = round(correlations_log_log,2),
                   collinearity_mean = round(collinearity_mean,2),
                   collinearity_mean_top3 = round(collinearity_mean3,2),
                   collinearity_mean_top5 = round(collinearity_mean5,2),
                   
                   collinearity_f1 = collinearity_f1,
                   collinearity_c1 = round(collinearity_c1,2),
                   collinearity_f2 = collinearity_f2,
                   collinearity_c2 = round(collinearity_c2,2),
                   collinearity_f3 = collinearity_f3,
                   collinearity_c3 = round(collinearity_c3,2)
                   )
featureStat = featureStat[order(-featureStat$abs_correlations),]
library("knitr")
kable(featureStat)
```



## Feature Selection

```{r}
set.seed(20190801)

data = train[, which(names(train) %in% c(as.character(subset(featureStat, featureStat$abs_correlations>0.05)$features), "SalePrice"))]

sample <- sample.int(n = nrow(data), size = floor(.7*nrow(data)), replace = F)

training = data[sample,]
testing  = data[-sample,]
```


```{r}
# Calculate RMSE
cal_rmse = function(y, y_hat){
  n = length(y)
  sqrt(sum((y - y_hat) ^ 2) / n)
}

envaluate_model = function(model, data){
  actual = log(data$SalePrice)
  predicts = log(predict(model, newdata = data) + 40)
  rmse = cal_rmse(actual, predicts)
  rmse
}
```

```{r}
fit = lm(SalePrice ~ ., data = training)
#summary(model1)
envaluate_model(fit, training)
envaluate_model(fit, testing)

fit_selected = step(fit,trace = 0)
envaluate_model(fit_selected, training)
envaluate_model(fit_selected, testing)

```

```{r}
fit = lm(SalePrice ~ . + (OverallQual + GrLivArea + GarageCars + TotalBsmtSF + X1stFlrSF  + MasVnrArea + Fireplaces+ YearBuilt ) ^2 +YearBuilt:TotalBsmtSF:X1stFlrSF + YearBuilt:MasVnrArea:GarageCars + log(LotArea)  + log(GrLivArea)+log(X1stFlrSF)+log(GarageArea) , data = training)
#summary(model1)
envaluate_model(fit, training)
envaluate_model(fit, testing)

fit_selected = step(fit,trace = 0)
envaluate_model(fit_selected, training)
envaluate_model(fit_selected, testing)


#coef(fit_selected)
```

Transform 

- Log Transform 
- Feature range is larger (Area)
log(LotArea)  + log(GrLivArea)+log(X1stFlrSF)+log(GarageArea)

Interaction

For top important features

- OverallQual
- GrLivArea
- GarageCars
- GarageCars
- YearBuilt
- YearRemodAdd

Collinearity

- Year based: 

  YearBuilt - GarageYtBlt - YearRemodAdd - OverallQual
- Area based

  GrLivArea - TotRmsAbvGrd - X2ndFlrSF - FullBath
  
  TotalBsmtSF - X1stFlrSF - OverallQual - GarageArea
  
- Garage

  GarageCars - GarageArea - GarageYtBlt - OverallQual
  
- First Floor

  X1stFlrSF - TotalBsmtSF - GrLivArea - GarageArea
  
- Second Floor

  X2ndFlrSF - GrLivArea - HalfBath - FullBath
- Lot 

  LotFrontage
  LotArea

## Model Selection



```{r}
#fit = lm(log(SalePrice) ~ . + YearBuilt:OverallQual + YearRemodAdd:OverallQual + OverallQual:TotalBsmtSF + OverallQual:GrLivArea + OverallQual:FullBath + GrLivArea:OverallQual + log(LotArea)  + log(GrLivArea)+log(X1stFlrSF)+log(GarageArea) , data = training)

fit = lm(log(SalePrice) ~ . + (OverallQual + GrLivArea + GarageCars + TotalBsmtSF + X1stFlrSF  + MasVnrArea + Fireplaces+ YearBuilt ) ^2 +YearBuilt:TotalBsmtSF:X1stFlrSF + YearBuilt:MasVnrArea:GarageCars + log(LotArea)  + log(GrLivArea)+log(X1stFlrSF)+log(GarageArea) , data = training)

cal_rmse(log(training$SalePrice), predict(fit, newdata = training))
cal_rmse(log(testing$SalePrice), predict(fit, newdata = testing))

```

AIC

```{r}
fit_aic = step(fit,trace = 0)
cal_rmse(log(training$SalePrice), predict(fit_aic, newdata = training))
cal_rmse(log(testing$SalePrice), predict(fit_aic, newdata = testing))

fit_aic
```

BIC
```{r}
n = nrow(data)

fit_bic = step(fit,trace = 0, k = log(n))

cal_rmse(log(training$SalePrice), predict(fit_bic, newdata = training))
cal_rmse(log(testing$SalePrice), predict(fit_bic, newdata = testing))
```


Interaction


```{r}
fit = lm(log(SalePrice) ~ .^2, data = training)

cal_rmse(log(training$SalePrice), predict(fit, newdata = training))

cal_rmse(log(testing$SalePrice), predict(fit, newdata = testing))
```

